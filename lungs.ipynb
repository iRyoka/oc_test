{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сегментация легких ###\n",
    "\n",
    "### Анамнез ###\n",
    "1. В целом легкие представляют из себя два связных темных пятна на снимках\n",
    "2. Тем не менее, на ряде изображений этот критерий существенно нарушается: иногда сердце мимет практически такую же проницеамость и отличимо лишь по контурам; иногда в легкие вдаются костные выросты (грдина? искривленный позвоночник), которые на метках исключены. В то же время, например, ключицы входят в облатсь легких, т.к. находятся \"перед\" ними. Поэтому полагатся только на интенсивность нельзя.\n",
    "3. Изображений достаточно много, чтобы, с учетом аугментаций, натренировать небольшую сеть.\n",
    "\n",
    "### Архитектура сети ###\n",
    "\n",
    "Нейросетевая часть очень похожа на задание 1. Все так же UNet4, по сути, единственный вариант, доступный по вычислительной мощности и способности обучаться на малом наборе данных. \n",
    "\n",
    "Для тренировки из изображения вырезается случайный кусок от 0.8 до 1.0 площади исходного изображения, и маштабируется до 128*128. Это несколько насыщает тренировочные данные, не изменяя их типичных особенностей. Например, нерезка на малые куски или отржения наверняка лишь ухудшили бы результат, так как распределение валидационных данных обладало бы общими особенностями (e.g. сердце слева), поторыми не обладал бы тренировочный датасет.\n",
    "\n",
    "Я тренировал сеть при помощи `Adam`, `lr=0.01`, коэффициент затухания `lr=0.9999`, 1 эпоха == длине тренировочного датасета (52 шт), батч = 4 избражения. Результаты проверялись после 100 и 300 эпох тренировки. 300 эпох занимает на моей машине ~45 минут.\n",
    "\n",
    "### Метрики ###\n",
    "На мой взгляд, для масок крупных объектов хорошей метрикой для бинарной сегментации является IOU: ее высокие значения обеспечивают, что маски \"геометрически\" близки. При этом, например, ошибка в виде тонкой линии (которую впоследствии легко исправить пост-процессингом, как в первом задании), внесет существенно меньший вклад, чем круглое пятно (которое, например, на границе областей устаранить непросто). Это отвечает геометрической интуиции понятия \"хорошего решения\".\n",
    "\n",
    "Также я вычисляю попиксельный F1_score в основном потому, что он остался у меня от первой задачи.и его легко считать. Для бинарной классификации есть и более аккуратные метрики, например коэффициент Мэтьюса. На сколько мне известно, F1 ведет себя *принципиально неадекватно* в случае существенного дисбаланса классов. На картинках, где легкие занимают примерно 1/3 площади и она должна вполне хорошо выражать успешность того или иного алгоритма. Опять же, время не резиновое и часть углов приходится срезать. На практике метрику все равно пришлось бы выбирать прагматически, исходя из имеющиейся задачи. Например, если важна мажоранта области, нужно с большим весом учитывать ложно отрицательные пиксели, если минранта -- то ложно положительные и т.д.\n",
    "Опять, же достаточно хорошими геометрическими инвариантами являются площадь и периметр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data2\n",
    "import modeltools2\n",
    "import os\n",
    "from unet import UNet\n",
    "import torch, torch.utils, torch.utils.data\n",
    "from torchsummary import summary\n",
    "import modeltools1\n",
    "import datetime\n",
    "import torchvision\n",
    "import sklearn, sklearn.metrics\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "data_dir = \"../02_image_segmentation2/xray-lung-segmentation\"\n",
    "train_file = \"idx-trn0.txt\"\n",
    "val_file = \"idx-val0.txt\"\n",
    "\n",
    "out_dir = \"out2\"\n",
    "if not os.path.exists(out_dir): os.mkdir(out_dir)\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "weights_path = None\n",
    "\n",
    "# comment all lines beow to train the UNet from scratch\n",
    "# weights after 300 epochs of training\n",
    "weights_path = \"lungs_weights300.dat\"\n",
    "\n",
    "# weights after 100 epochs of training\n",
    "# weights_path = \"lungs_weights100.dat\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data2.LungsDataset(data_dir, train_file)\n",
    "val_dataset = data2.LungsDataset(data_dir, val_file)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = 4, num_workers=2, \n",
    "    pin_memory=True)\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size = 4, num_workers=2, \n",
    "    pin_memory=True)\n",
    "\n",
    "# train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 128, 128]             320\n",
      "              ReLU-2         [-1, 32, 128, 128]               0\n",
      "       BatchNorm2d-3         [-1, 32, 128, 128]              64\n",
      "            Conv2d-4         [-1, 32, 128, 128]           9,248\n",
      "              ReLU-5         [-1, 32, 128, 128]               0\n",
      "       BatchNorm2d-6         [-1, 32, 128, 128]              64\n",
      "         MaxPool2d-7           [-1, 32, 64, 64]               0\n",
      "         DownBlock-8  [[-1, 32, 64, 64], [-1, 32, 128, 128]]               0\n",
      "            Conv2d-9           [-1, 64, 64, 64]          18,496\n",
      "             ReLU-10           [-1, 64, 64, 64]               0\n",
      "      BatchNorm2d-11           [-1, 64, 64, 64]             128\n",
      "           Conv2d-12           [-1, 64, 64, 64]          36,928\n",
      "             ReLU-13           [-1, 64, 64, 64]               0\n",
      "      BatchNorm2d-14           [-1, 64, 64, 64]             128\n",
      "        MaxPool2d-15           [-1, 64, 32, 32]               0\n",
      "        DownBlock-16  [[-1, 64, 32, 32], [-1, 64, 64, 64]]               0\n",
      "           Conv2d-17          [-1, 128, 32, 32]          73,856\n",
      "             ReLU-18          [-1, 128, 32, 32]               0\n",
      "      BatchNorm2d-19          [-1, 128, 32, 32]             256\n",
      "           Conv2d-20          [-1, 128, 32, 32]         147,584\n",
      "             ReLU-21          [-1, 128, 32, 32]               0\n",
      "      BatchNorm2d-22          [-1, 128, 32, 32]             256\n",
      "        MaxPool2d-23          [-1, 128, 16, 16]               0\n",
      "        DownBlock-24  [[-1, 128, 16, 16], [-1, 128, 32, 32]]               0\n",
      "           Conv2d-25          [-1, 256, 16, 16]         295,168\n",
      "             ReLU-26          [-1, 256, 16, 16]               0\n",
      "      BatchNorm2d-27          [-1, 256, 16, 16]             512\n",
      "           Conv2d-28          [-1, 256, 16, 16]         590,080\n",
      "             ReLU-29          [-1, 256, 16, 16]               0\n",
      "      BatchNorm2d-30          [-1, 256, 16, 16]             512\n",
      "        DownBlock-31  [[-1, 256, 16, 16], [-1, 256, 16, 16]]               0\n",
      "  ConvTranspose2d-32          [-1, 128, 32, 32]         131,200\n",
      "             ReLU-33          [-1, 128, 32, 32]               0\n",
      "      BatchNorm2d-34          [-1, 128, 32, 32]             256\n",
      "      Concatenate-35          [-1, 256, 32, 32]               0\n",
      "           Conv2d-36          [-1, 128, 32, 32]         295,040\n",
      "             ReLU-37          [-1, 128, 32, 32]               0\n",
      "      BatchNorm2d-38          [-1, 128, 32, 32]             256\n",
      "           Conv2d-39          [-1, 128, 32, 32]         147,584\n",
      "             ReLU-40          [-1, 128, 32, 32]               0\n",
      "      BatchNorm2d-41          [-1, 128, 32, 32]             256\n",
      "          UpBlock-42          [-1, 128, 32, 32]               0\n",
      "  ConvTranspose2d-43           [-1, 64, 64, 64]          32,832\n",
      "             ReLU-44           [-1, 64, 64, 64]               0\n",
      "      BatchNorm2d-45           [-1, 64, 64, 64]             128\n",
      "      Concatenate-46          [-1, 128, 64, 64]               0\n",
      "           Conv2d-47           [-1, 64, 64, 64]          73,792\n",
      "             ReLU-48           [-1, 64, 64, 64]               0\n",
      "      BatchNorm2d-49           [-1, 64, 64, 64]             128\n",
      "           Conv2d-50           [-1, 64, 64, 64]          36,928\n",
      "             ReLU-51           [-1, 64, 64, 64]               0\n",
      "      BatchNorm2d-52           [-1, 64, 64, 64]             128\n",
      "          UpBlock-53           [-1, 64, 64, 64]               0\n",
      "  ConvTranspose2d-54         [-1, 32, 128, 128]           8,224\n",
      "             ReLU-55         [-1, 32, 128, 128]               0\n",
      "      BatchNorm2d-56         [-1, 32, 128, 128]              64\n",
      "      Concatenate-57         [-1, 64, 128, 128]               0\n",
      "           Conv2d-58         [-1, 32, 128, 128]          18,464\n",
      "             ReLU-59         [-1, 32, 128, 128]               0\n",
      "      BatchNorm2d-60         [-1, 32, 128, 128]              64\n",
      "           Conv2d-61         [-1, 32, 128, 128]           9,248\n",
      "             ReLU-62         [-1, 32, 128, 128]               0\n",
      "      BatchNorm2d-63         [-1, 32, 128, 128]              64\n",
      "          UpBlock-64         [-1, 32, 128, 128]               0\n",
      "           Conv2d-65          [-1, 2, 128, 128]              66\n",
      "================================================================\n",
      "Total params: 1,928,322\n",
      "Trainable params: 1,928,322\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 131.00\n",
      "Params size (MB): 7.36\n",
      "Estimated Total Size (MB): 138.42\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = UNet(in_channels = 1, out_channels=2, n_blocks = 4).to(device)\n",
    "summary(model, (1, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "optim_params = model.parameters()\n",
    "optim = torch.optim.Adam(optim_params, lr=lr)\n",
    "# loss = torch.nn.CrossEntropyLoss()\n",
    "loss = modeltools1.FocalLoss(reduction=\"mean\")\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma =0.9999)\n",
    "epochs = 10 #optimal value is 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f30b4736c64ea990298ece537bac5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch 52, loss: 0.06828171014785767, lr: [0.009947137566032547]\n",
      "Epoch 1, batch 52, loss: 0.05588827282190323, lr: [0.009894554575757594]\n",
      "Epoch 2, batch 52, loss: 0.04341818764805794, lr: [0.009842249551967755]\n",
      "Epoch 3, batch 52, loss: 0.023056985810399055, lr: [0.009790221025264544]\n",
      "Epoch 4, batch 52, loss: 0.021275952458381653, lr: [0.00973846753401706]\n",
      "Epoch 5, batch 52, loss: 0.017449628561735153, lr: [0.00968698762432094]\n",
      "Epoch 6, batch 52, loss: 0.018327899277210236, lr: [0.009635779849957513]\n",
      "Epoch 7, batch 52, loss: 0.020231978967785835, lr: [0.00958484277235318]\n",
      "Epoch 8, batch 52, loss: 0.015873288735747337, lr: [0.009534174960538981]\n",
      "Epoch 9, batch 52, loss: 0.014763027429580688, lr: [0.009483774991110418]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = []\n",
    "if (\"weights_path\" in locals() or \"weights_path\" in globals()) and weights_path:\n",
    "    model.load_state_dict(torch.load(weights_path))\n",
    "else:\n",
    "        train_dataset.train()\n",
    "        model.train()\n",
    "        modeltools1.train_model(model, loss, optim, scheduler, train_dataloader,\n",
    "                num_epochs = epochs, device = device) \n",
    "        model.cpu()\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "        torch.save(model.state_dict(), './lungs_weights'+current_time+\".dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже сетка прогоняется на тренировочном и валидационных датасетах. В папке out2 сохранаются исходное изображение (для наглядности), предсказанная маска и исходная метка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f699e930a77541f8a6ba78f5915725ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train F1 score 0.9431135360231097, IOU score: 0.893511507871016\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79df404025804ea6a96dc95b8516bb91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val F1 score 0.9399836691081003, IOU score: 0.8892735156794669\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "train_dataset.eval()\n",
    "val_dataset.eval()\n",
    "F1_score, IOU_score = modeltools2.eval_model_on_dataloader(model, train_dataloader, device, \"out2/img\")\n",
    "print(f\"train F1 score {F1_score}, IOU score: {IOU_score}\")   \n",
    "F1_score, IOU_score = modeltools2.eval_model_on_dataloader(model, val_dataloader, device, \"out2/img\")\n",
    "print(f\"val F1 score {F1_score}, IOU score: {IOU_score}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результаты ###    \n",
    "    \n",
    "    Эпох    | F1 train  | IOU train | F1 val    | IOU val  | Loss\n",
    "    10      | 0.844359  | 0.7507    | 0.820202  | 0.723840 | 0.0147\n",
    "    100     | 0.968350  | 0.938900  | 0.956945  | 0.923821 | 0.0075\n",
    "    300     | 0.9749    | 0.9511    | 0.9585    | 0.9266   | 0.0037"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Глазометрическое изучение результатов показло, что разница между предсказаниями сетки после 100 и 300 эпох тренировки мало сущетвенна. Из плюсов, это говорит в пользу адекватности наших метрик, они тоже изменились несильно. Из минусов, надежда, что ту же сеть можно натренировать на тех же данных лучше, слабая. Ниже привожу несколько примеров работы сетки (300 эпох) на валидационном датасете.\n",
    "\n",
    "Зеленым отмечен пример незначительной ошибки, которые элементарно устраняются пост-процессингом. Красным -- ошибки, которые устранить сложнее. В основном они возникают на снимках с уникальными анатомическими особенностями: сетке просто не хватило таких данных в трен-датасете. Ну и одно изображение просто супер неконтрастное, а я не делаю никакой входной коррекции, равно как и соответствующих аугментаций. Результат кажется мне достаточно хорошим.\n",
    "![](lungs_demo1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эвристический алгоритм ###\n",
    "\n",
    "На моей машине инференс проходит со скоростью 8 снимков в секунду вместе с подсчетом метрик и сохранением файлов и в целом сеть дает хороший результат, но эту задачу можно решать и прямым алгоритмом. Это дает больший контроль над морфологией объекта, поэтому в некоторых случах может быть предпочтительным. \n",
    "\n",
    "Я попробовал скормить эти картинки ванильному MSER (в реализации opencv 4.5.5), но выявилось несколько проблем: а) он сильно зависит от контрастности изображения. С этим можно было бороться посредством какого-то варианта автоматической гамма-коррекции. Что гораздо хуже, в силу своей природы, MSER объединяет области в объекты несколькими способами. Так, например, появляются объекты класса легкое+сердце, легкое, легкое без куска и придумать простой алгоритм различения \"правильного варианта\" мне не удалось. Более того, не видя исходного снимка, я бы и сам не взялся сделать такой выбор. Вот пример объектов, которые MSER находит на одном и том же изоражении. Кроме первого, это все вариации левого легкого.\n",
    "![](lungs_demo2.png)\n",
    "\n",
    "В то же время, более примитивный метод Отсу, который по сути являается статистически аккуратным способом выбрать бинарную границу освещенности объектов перднего плана по крайней мере дает достаточно стабильный результат. Единственно, что на ряде изображений он срабатыват на черный фон вокруг снимка, но это легко исправить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1bc1f8c35bd18689d84db61d33d5c58e75d3454474558482af5176b6a1531d50"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
